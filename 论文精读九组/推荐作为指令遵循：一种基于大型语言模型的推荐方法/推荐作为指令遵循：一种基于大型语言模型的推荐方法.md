​                                   **推荐作为指令遵循：一种基于大型语言模型的推荐方法**

**论文概要**

在过去的几十年里，推荐系统无论是在研究界还是工业界都受到了广泛的关注，大量的研究致力于开发有效的推荐模型。这些模型主要基于用户的历史行为数据（通常以物品ID的形式存在）来学习用户的潜在偏好，然后估计用户与物品之间的匹配关系以进行推荐。

受到近期大型语言模型（LLMs）的启发，我们采取了一种不同的方法来开发推荐模型，将推荐视为LLMs的指令遵循。关键思想是，用户的偏好或需求可以通过自然语言描述（称为指令）来表达，这样LLMs就可以理解并进一步执行该指令以完成推荐任务。我们没有使用LLMs的公共API，而是对一个开源的LLM（3B Flan-T5-XL）进行了指令调优，以更好地将LLMs适应于推荐系统。为此，我们首先设计了一个通用的指令格式，用于以自然语言描述用户的偏好、意图、任务形式和上下文。然后，我们手动设计了39个指令模板，并自动生成了大量用户个性化的指令数据（252K条指令），具有不同类型和偏好的意图。为了证明我们方法的有效性，我们将指令模板实例化到几个广泛研究的推荐（或搜索）任务中，并使用真实数据集对这些任务进行了广泛的实验。实验结果表明，我们提出的方法在这些评估任务上优于几个有竞争力的基线，包括强大的GPT-3.5。我们的方法为开发更友好的推荐系统提供了思路，用户可以与系统自由沟通，并通过自然语言指令获得更准确的推荐。

**关键词**
大型语言模型，指令调优，推荐系统

**介绍**

如今，推荐系统已广泛应用于各种应用平台，旨在满足用户需求并促进可用资源的利用（或销售）。与早期的方法一样，协同过滤算法[24，30]是通过基于相似的品味（用户方面）或相似的特性（项目方面）来推荐物品。随后，采用了矩阵分解[23]和神经网络[15，21]来开发推荐模型，这些模型可以捕获更复杂的用户偏好并学习更准确的用户-物品关系。尽管取得了巨大的进步，但现有的推荐算法主要是通过拟合用户-物品交互数据来训练的，缺乏在未见过的设置（例如新用户或新任务）上的泛化能力。此外，用户在传统的推荐算法中是被动参与的，无法以灵活的形式明确表达他们的真实需求。

![9e3116495bfd889a59f115328919fe5](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\9e3116495bfd889a59f115328919fe5.png)

最近，预训练的大型语言模型（LLM）[34，41，44]（例如T5[29]和GPT-3[4]）在各种自然语言任务上显示出非凡的能力，这为开发更通用和有效的推荐系统提供了启示[2，6，7，13，17，18]。例如，研究表明语言模型可以提高推荐系统的可迁移性[9，17，18]，并增强用户与系统之间的交互[6，13，35]。然而，语言模型是建立在自然语言文本上的，它们并不直接适用于推荐系统，因为推荐系统需要处理行为数据而不是文本数据。为了弥合语言模型与推荐系统之间的鸿沟，一种有前途的方法是考虑将行为建模作为语言建模[6，12，13，26]：它将推荐任务格式化为自然语言文本的形式，然后将其视为语言处理任务。在这种方法中，两个基本问题对于成功推荐物品至关重要：

（1）推荐的指令介绍。
我们正式介绍了推荐系统中指令的概念。尽管之前的研究[2，13]中有类似的努力，但我们讨论了LLM上下文中用户需求的表达，并将推荐视为通过指令遵循的特定任务。此外，我们为编写指令提供了详细的设计，并为其解决了具有特定用户需求或偏好的不同推荐任务。

（2）为推荐调整指令的LLM。
为了适应LLM的推荐系统，我们进一步采用指令调整来根据推荐目标优化LLM。为此，我们自动生成了大量面向推荐的指令数据，用于调整LLM。指令调整是激发LLM对推荐任务的能力的关键，它进一步使LLM能够泛化到不同的用户需求或请求上。

为此，我们为推荐系统提出了一种指令调整方法，名为InstructRec，这是一种新的推荐范式，允许用户以自然语言的形式自由表达他们的具体需求。为了开发这个推荐系统，我们的基础模型建立在3B Flan-T5-XL [5]之上。作为我们方法的关键，设计指令格式和构建指令数据非常重要。首先，我们通过整合四大部分——偏好、意图、任务形式和上下文——来制定指令格式。正如我们将看到的那样，这种指令形式可以覆盖各种具体的用户需求，尤其适合格式化不同的推荐任务。其次，我们手动设计了39个粗粒度的指令模板来覆盖交互场景，并自动生成了252K个细粒度的用户个性化指令数据，这些数据具有不同类型的用户偏好和意图。为了生成高质量的指令数据，我们利用GTP-3.5根据真实的历史数据（例如，历史交互或评论文本）来生成用户偏好或意图[36]。此外，我们提出了一系列有用的策略来增加指令的多样性，因为这对于提高指令调整的性能很重要[5，37]。通过用这些面向推荐的指令数据调整LLM，基础模型可以很好地适应推荐系统，并学会遵循用户的指令来完成相应的推荐任务。尽管我们只考虑了单轮指令跟随，但将当前方法扩展到多轮对话场景是很有前景的。这种LLM的任务专业化方法可以增强推荐模型的整体泛化能力，并提高推荐系统中的用户体验。

为了评估所提出的方法，我们利用现实世界的数据集构建了广泛的交互场景，并进行了大量的实验。与几个具有竞争力的基线相比，所提出的方法表现出令人满意的性能。实验结果还表明，InstructRec可以有效地提高LLM满足多样化用户需求的能力。此外，对于保留的指令和领域，该方法的性能也验证了其具有更好的泛化能力。这项工作的主要贡献总结如下：

• 我们将推荐视为LLM的指令跟随，并引入了一种新的推荐范式，允许用户在推荐中自由表达其多样化的信息需求。
• 我们设计了一种灵活且通用的指令形式，并自动生成了大量高质量的指令数据。此外，我们还专门为推荐系统微调了一个3B语言模型。
• 大量的实验证明了我们的方法在推荐系统中各种任务场景的有效性和泛化能力。

**方法论**

在本节中，我们介绍了为推荐系统提出的名为InstructRec的指令调整方法。当用户与推荐系统交互时，我们的方法允许用户以自然语言指令的形式自由表达他们的信息需求。为了开发我们的方法，我们首先为推荐设计了一种特定的指令格式，并在第2.1节中正式介绍了指令中的三个关键方面（即偏好、意图和任务形式）。接下来，我们在第2.2节中介绍了如何根据各种实例化，借助LLM构建具有不同偏好、意图和任务形式的指令数据，以及增加指令多样性的几种策略。最后，我们在第2.3节中讨论了如何使用这些生成的指令数据对基础LLM进行微调，以实现更以用户为中心的推荐。

**2.1 推荐指令格式**

为了使LLM能够通过指令为用户执行个性化的推荐任务，第一步是设计一个合适的指令格式。该格式旨在有效地揭示用户的模糊/具体意图，提供用户的隐式/显式偏好，并明确任务设置。在本部分中，我们为推荐提出了一种包含三个关键方面的统一指令格式，然后针对不同的交互场景对其进行实例化。

2.1.1 指令中的关键方面。为了设计一个灵活且可扩展的指令格式，我们主要考虑与用户需求表达相关的三个方面，即偏好、意图和任务形式。我们在图2中展示了指令格式的示意图。接下来，我们将详细介绍这三个方面及其代表性类型。

**偏好（P）**。偏好指的是用户对商品属性或特性的个性化喜好。在我们的指令格式中，它旨在捕捉用户固有的长期偏好。根据个性化的程度，用户偏好可以分为以下三种类型：

• 无偏好（P0）。在这种情况下，推荐系统无法获取有关用户偏好或个人资料的可用信息，例如冷启动场景或出于隐私考虑，这会导致非个性化的推荐。

• 隐式偏好（P1）。它指的是有关用户的上下文信息（例如，用户的个人资料或历史交互记录）是可用的，但没有明确暴露出对项目的底层偏好。在现有文献中，隐式交互行为通常被称为隐式反馈[19，22]，这种反馈更容易收集，但可能存在噪声。在格式化历史交互记录时，我们没有像P5[13]中那样直接使用项目ID来表示项目，而是使用项目标题来格式化项目文本。

• 显式偏好（P2）。除了隐式偏好之外，用户在某些情况下还可能直接表达他们的偏好。这种显式反馈更准确但难以获得。在这里，我们主要考虑用户在自然语言文本中明确表达偏好的情况（例如，用户评论）。虽然我们的格式中也可以轻松地将显式交互记录（例如，评分或点赞）转化为语言，但我们没有直接考虑这一点。

**意图（I）**。与长期的偏好相比，用户的意图是指他们对某些类型的商品的更直接的需求，这可能与用户的长期偏好不同。受Su等人的启发[32]，我们根据清晰度的不同将用户意图分为三类。

• 无意图（I0）。在交互过程中，用户可能缺乏明确的下一个交互目标，期望通过推荐系统和探索性交互来发现潜在的兴趣。

![1708778566856](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778566856.png)

• 模糊的意图（I1）。在这种情况下，用户对自己的需求表现出模糊的认知，例如对商品所需特性的描述，但无法明确识别出特定的商品（例如，“给我儿子的一些礼物”）。

• 具体的意图（I2）。在这种情况下，用户有明确的需求，要求系统优先考虑他们的请求并提供满足特定需求的合适商品（例如，“蓝色、便宜、iPhone13”）。

任务形式（T）。除了用户偏好和意图外，制定指令的另一个关键方面是LLM执行的具体任务形式。类似于[7]，我们考虑了推荐任务的三种潜在形式：

• 单点推荐（T0）。LLM被指示检查候选商品是否适合用户，其中匹配关系是基于用户的信息需求和商品特性来确定的。

• 成对推荐（T1）。在这种情况下，会调用一对商品之间的比较，并指示LLM从这一对商品中选择更合适的商品。

• 匹配（T2）。作为匹配（即候选生成）模块，LLM从整个商品语料库中生成潜在的候选商品。这些候选商品应该是高质量的资源，并且对目标商品有很好的覆盖。

• 重新排序（T3）。与T2指示LLM作为匹配模块不同，此情况下LLM被用作重新排序器。也就是说，LLM被指示对检索到的候选商品进行重新排序，从而实现更准确的推荐。

除了上述三个部分外，我们还可以添加有关用户情况的其他有用上下文信息（例如，时间和地点），称为上下文。总的来说，我们可以灵活地以自然语言文本的形式整合这四个部分。

**2.1.2 各种交互场景的实例化。**

在这一部分，我们讨论如何为不同的现实交互场景实例化上述指令格式。我们在表1中提供了一些指令实例化的例子。接下来，我们介绍几个有代表性的实例化。

• ⟨P1/P2，I0，T3⟩。在这种情况下，我们将P1或P2与I0（无意图）结合，重点关注用户偏好。在执行这些指令时，LLM充当传统的推荐系统。我们还可以结合两种偏好，从而指示LLM使用个性化的提示（P2）进行推荐[21，39]。

![1708778585993](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778585993.png)

• ⟨P0，I1/I2，T3⟩。我们将P0与I1或I2结合，以实例化第二种类型的指令。特别地，LLM充当传统的检索器，用于处理用户的模糊或具体查询[20]。

• ⟨P1/P2，I1/I2，T3⟩。我们结合用户偏好（P1/P2）和意图（I1/I2），旨在重新排序候选商品。这样的任务也可以被视为个性化搜索，其中用户偏好和意图（查询）可用于满足用户需求[1，3]。

通过这种指令格式，我们可以实例化不同的交互场景。请注意，在我们的设置中，推荐和搜索之间没有明确的界限，因为两者都可以以类似的方式制定（参见对⟨P1/P2，I1/I2，T3⟩的讨论）。

在上述内容中，我们主要讨论了具有T3的任务形式，因为由于推理成本较高，LLM目前更适合于重新排序阶段。相比之下，我们可以使用其他任务形式，如T2进行训练，这是一个更困难的任务设置。在我们的评估中，提高指令的多样性被证明是有效的。

**2.2 指令生成**
根据2.1节中介绍的指令格式，我们接下来基于可用的交互数据模拟用户偏好和意图来生成指令数据。然而，很难获得大量明确揭示用户真实偏好或意图的数据。最近，一些研究尝试使用自动提示策略（例如self-instruct [36]），通过提示一个由指令调优的LLM（称为教师LLM）来生成高质量的指令。受此启发，我们使用一个强大的教师LLM（即GPT-3.5）来通过提示用户的历史交互和评论来为每个用户生成此类个性化信息，这传达了有关偏好和意图的丰富信息。接下来，我们首先介绍指令生成的流程，然后评估生成指令的质量。

**2.2.1 注释指令中的方面。**为了更好地通过自然语言指令格式化用户需求的表达，我们首先根据各种交互场景的实例化（见2.1.2节）手动创建粗粒度的模板。随后，我们用从交互数据中提取或由教师LLM生成的特定用户偏好和意图（指细粒度的用户个性化指令）来填充这些模板。接下来，我们详细说明构建过程。

偏好注释。我们考虑到个性化的不同程度，使用不同的策略来生成用户偏好。对于隐式偏好𝑃1，我们采用项目的标题作为其表示，并利用用户的历史交互来填充指令模板，这可以实例化为“用户以前购买过以下项目：{[MASK]}”。而对于显式偏好𝑃2，由于数据集中通常没有用户偏好的明确描述，因此我们采用教师LLM（即GPT-3.5）来充当用户，并根据历史交互生成偏好的明确表达。GPT-3.5显示出强大的文本理解能力，它可以根据历史交互行为生成关于用户偏好或意图的非常有意义的表达。下面是一个由GPT-3.5生成用户偏好的例子：

[原始行为序列]：“1. Resident Evil: Revelations 2 - PlayStation 4 → 2. Resident Evil 4 - PlayStation 4 Standard Edition。”

[生成的显式偏好]：“他喜欢基于恐怖且叙事性强的游戏。”

意图注释。同样，我们可以生成不同程度清晰度的用户意图，包括模糊的意图𝐼1和具体的意图𝐼2。为了推导出模糊的意图，由于评论提供了有关用户个人品味和进行特定交互的原因的有价值证据，我们考虑从目标评论（与目标项目相关的评论）中提取意图。特别是，我们采用教师LLM来处理这些评论并提取意图。下面是一个从评论文本中提取用户意图的例子：

[原始目标评论]：“我儿子喜欢...这个游戏。我很高兴我给他买了这个游戏。”

[生成的模糊意图]：“我喜欢给我儿子买他喜欢的游戏。”

至于具体的意图，当用户使用推荐系统时（例如在电子商务平台上购买视频游戏），他们有时会对某些项目有明确的需求。如先前的工作[1，3]所述，目标项目的类别是反映用户真实意图的重要证据。因此，我们通过将多个相关的类别标签连接成一个意图表达式，从目标项目的类别信息中提取用户的具体意图：

[生成的具体意图]：“视频游戏、电脑、配件、游戏鼠标。”

与用户历史交互中提取的模糊意图相比，从目标项目信息中提取的意图更为具体，并可以直接反映用户的真实意图。

**任务形式标注。**在本文中，我们主要关注三种任务形式：𝑇0、𝑇2和𝑇3。具体来说，对于点对点推荐𝑇0，我们将指令制定为：“基于<用户相关信息>，用户接下来是否可能与<目标项目>进行交互？”，系统应回答“是”或“否”。对于匹配任务𝑇2，指令制定为“预测下一个可能的项目”。而对于重排任务𝑇3，指令中融入了一个候选项目列表：“从以下<候选项目>中选择一个”。虽然目前我们不包括成对推荐𝑇1，但它可以很容易地融入我们提出的框架中。

2.2.2 增加指令的多样性。最近的研究[5，37]已经证明了增加指令的数量和多样性的有效性。因此，为了进一步提高指令调整的性能，我们提出使用几种策略来增加指令数据的多样性。

将任务反转。这种策略指的是正常指令的输入和输出之间的交换[37]。在我们的案例中，我们要求LLM不仅要根据用户偏好或意图推荐适当的项目，还要根据推荐的反馈推断他们潜在的信息需求。这样的任务可以帮助LLM理解用户行为与潜在信息需求之间的关系。下面是一个指令及其反转版本的示例：

[正常指令]：“用户搜索了<查询>，你能生成回应他查询的项目吗？”

[反转指令]：“用户想买：<目标项目>，但他不知道如何制定查询，请帮他生成。”

强化偏好与意图之间的相关性。这指的是在一个指令中，用户揭示的短期意图与长期偏好应该高度相关。

[意图→偏好]：“用户已经搜索了<查询>并选择了产品<目标项目>。请基于他的查询和选择，推断他的历史交互。”

[偏好→意图]：“用户具有以下<历史交互>，你可以推断他们的偏好。请基于他的偏好，预测用户下一个查询以及他可能购买的项目。”

链式思考（CoT）类推理。这种策略在中间推理步骤中添加额外的解释，使LLM能够执行复杂的推理任务[38]。为了将这个想法应用于我们的任务，它指的是从用户的隐式行为到导致最终推荐的明确偏好或意图的推理过程：

[CoT指令]：“给定用户的<历史交互>，请推断他的偏好并向他推荐合适的项目。”

[期望的回应]：“根据用户的历史交互，我们可以推断他的<偏好>。最后，我们向他推荐<目标项目>。”

![1708778618437](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778618437.png)

![1708778645458](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778645458.png)2.2.3 指令数据的统计与质量。基于上述步骤，我们首先手动设计了39个粗粒度的指令模板（见附录中的指令模板完整列表），涵盖了多种不同的交互场景。然后，我们借助教师LLM（即GPT-3.5）生成了总计252K个细粒度的用户指令，这些指令描述了用户各种类型和意图的偏好。生成的指令的统计信息总结在表2中。为了评估这些细粒度指令的质量，我们从每个描述用户偏好和意图的指令中随机抽取了100个实例进行评估。要求注释员根据其与用户数据（例如历史交互、目标项目和相关评论)的一致性来评估生成的指令的适当性。结果如图表3所示。在大多数情况下，教师LLM可以根据用户的特定信息生成适当的指令。它不仅限于原始信息，还可以通过利用编码的世界知识来生成更详细的指令。目前，只有69%的指令与用户当前的意图完全吻合，我们推测这受到了评论文本中包含的噪声的影响。我们将探索如何生成更准确的意图作为未来的工作。

**2.3 用于推荐的指令调优**
基于上述指令格式，我们接下来讨论如何为推荐系统调优LLM。我们首先介绍主干LLM，然后介绍优化和推理。

2.3.1 主干LLM。在这项工作中，我们的目标是开发一个能够遵循以用户为中心的指令来指定其需求的推荐模型。受最近LLM进展的启发[16，28，34，44]，我们的方法基于这样一个事实，即LLM在遵循用户的指令来解决各种任务方面表现出强大的能力。使用LLM作为推荐器，我们将推荐视为遵循指令的特定任务。已经表明，指令调优使LLM能够推广到以自然语言指令描述的未见过的任务[27，37]。因此，这种方法可以潜在地扩展到在应用系统中完成更多多样化的任务。然而，我们将讨论限制在推荐任务上。特别地，我们采用3B Flan-T5-XL[5]作为主干模型。由于Flan-T5已经基于T5[29]进行了大量指令数据的微调，因此它具有出色的遵循自然语言指令的能力。然而，用于调优Flan-T5的原始指令并不是专门为推荐系统设计的，因此无法有效地指导模型执行推荐任务。具体来说，Flan-T5采用编码器-解码器架构，支持最大上下文长度为512个令牌。在我们的方法中，我们使用与项目相关的文本（例如标题）来表示项目，这可能在格式化用户行为序列时导致输入长度过长。在这种情况下，我们必须截断输入序列，并可能导致性能不佳。研究人员可以替代地使用具有更长上下文长度的LLM，例如LLaMA[34]，来建模长的行为序列。

2.3.2 训练与推理。在这一部分，我们讨论如何使用生成的指令优化我们的基础LLM，以及如何使用它来解决推荐任务。

通过指令调优进行优化。利用生成的指令数据，我们可以通过指令调优来优化LLM，这本质上是一种有监督的微调方式。具体来说，我们首先根据不同类型的指令标注期望的系统响应（目标输出）。例如，当指示模型预测下一个项目时，目标输出被标注为目标项目。而对于像CoT这样的指令，目标输出被标注为用户对于特定交互的推理过程。由于指令和目标输出都可以以自然语言格式进行编写，我们可以将训练统一为序列到序列的方式。在形式上，我们优化目标输出的负对数似然如下：

L = 𝐵 ∑𝑘=1 |𝑌𝑘 | ∑𝑗=1 log 𝑃(𝑌𝑘,𝑗 | 𝑌𝑘,<𝑗 , 𝐼𝑘) , (1)

其中，𝑌𝑘 是第k个实例的期望系统响应，𝐼𝑘 是第k个实例的指令，𝐵 是批量大小。

![1708778669971](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778669971.png)

推理。通过指令调优，LLM已经被训练成遵循各种交互场景中的指令。在这一部分，我们展示了我们的方法在推荐系统中的应用。考虑到计算效率和模型容量，我们采用LLM作为重排器，根据用户的指令为候选人生成最终排名。在现实世界的系统中，用户的需求非常多样化，我们期望指令能够有效地捕捉不同的偏好或意图，并利用自然语言的通用性。具体来说，当为用户提供推荐服务时，系统首先会根据用户指令（即用户发出的指令）和其他有用信息（例如历史交互）选择适当的粗粒度指令模板。然后，我们使用诸如连接、插入和人称转换等操作将原始表达式转换为模型指令。然后，请求推荐器（即LLM）执行指定用户需求的模型指令。然而，由于LLM生成过程固有的随机性，存在生成超出候选集范围项目的潜在风险，特别是在使用集束搜索生成候选项目列表时。为了解决这个问题，类似于方程（1），我们直接将候选项目作为模型的解码器输入，并计算它们的可能性，以确定推荐的最终排名。

**2.4 讨论**

在这一部分，我们将提出的InstructRec与相关方法进行比较，从而突出我们方法的贡献。传统方法如SASRec [21]和LightGCN [14]通常依赖唯一标识符来表示用户和项目，并为推荐构建特定的偏好函数。然而，他们往往难以解决冷启动问题，因为新用户或新项目无法得到很好的表示。此外，传统的推荐方法侧重于用户被动接受推荐，可能无法准确捕捉真正的偏好。虽然用户可以主动请求搜索引擎检索相关项目[20，31]，但由于其能力有限，传统搜索引擎只能处理特定的用户查询。相比之下，我们的模型使用自然语言表述推荐任务，并利用LLM中的通用知识进行推荐，具有更好的泛化能力。此外，通过对具有不同类型用户偏好、意图和任务形式的指令进行微调，我们的模型可以有效地满足用户的多样化需求。

现有的LLM在推荐系统中的应用，如P5 [13]和M6-Rec [6]，将行为建模视为语言建模，其中推荐任务被表述为自然语言表达式。M6-Rec通过将各种上下文信息转换为顺序文本格式并纳入训练，减少对用户行为数据的依赖，从而在不同交互行为上实现强大的泛化能力。P5将论文表述为我们的方法设计和生成了面向推荐的指令，其中包含不同类型的偏好、意图和任务形式，这可以增强各种交互场景中的个性化。我们的方法与两项相关研究的比较如表4所示。

**3.实验**

在本节中，我们进行了实验来评估我们提出的InstructRec在几个方面的能力。

**3.1 实验设置**

3.1.1 数据集。我们分别使用Amazon2数据集的“Video Games”子集评估了我们的模型在容纳以用户为中心的指令方面的性能，以及使用Amazon数据集的“CDs & Vinyl”子集评估了我们的模型在未见过数据上的泛化能力。遵循以前的工作[18]，我们过滤掉了所有数据集中交互次数少于五次的冷门用户和项目。由于我们的主干网络Flan-T5的上下文限制为512个令牌，我们将生成的行为序列截断为最多20个项目。我们预处理后的数据集统计信息如表5所示。

![1708778694350](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778694350.png)

3.1.2 评估指标。我们采用 top-K 命中率（HR）和 top-K 归一化折扣累积增益（NDCG）来评估性能。在本文中，K 设置为 1、3 和 5。对于顺序推荐和个性化搜索等交互场景，我们遵循以前的工作[3，18，45]，采用留一法策略进行评估。具体来说，对于每个用户交互序列，最后一个项目及其相关评论用作测试数据，最后一个交互之前的项目和评论用作验证数据，剩余的交互记录用于训练。对于产品搜索等交互场景，我们将所有项目及其相关查询分为训练（80%）、验证（10%）和测试（10%）。在这种设置下，验证集和测试集的实例在训练阶段是不可见的，这增加了推理的难度。我们使用流行的开源推荐库 RecBole [40，42，43] 实现了一些基线。值得注意的是，对于不同类型的粗粒度指令，我们在验证集中评估获得最佳性能的指令的结果。我们将模型作为重新排序器，在测试集上评估（我们在第 3.3 节中进一步评估了更难的设置），并对所有测试实例的平均分数进行报告。每个实例的真实情况在九个随机采样的负面项目中排名。

**3.2 在各种用户信息需求上的总体表现**

为了证明我们的模型在容纳各种用户指令方面的有效性，我们根据这些指令在各种交互场景中的实例化情况进行了深入的实验（参见第2.1.2节的实例化情况）。接下来，我们将分别介绍不同场景中的这些实验，包括基线和性能比较。值得注意的是，除了引入专门针对特定交互场景的基线外，我们还进一步采用了text-davinci-003 3，这是通用GPT-3.5模型之一，作为比较的强大LLM基线。值得注意的是，由于该模型的成本较高，我们随机抽取了500个实例来评估其性能。尽管这不可避免地会引入一些随机性，但我们相信在这种设置下得出的结论对于探索通用LLM的推荐能力仍具有参考价值。

3.2.1 顺序推荐 ⟨𝑃1, 𝐼0,𝑇3⟩。我们首先通过使用用户的隐式偏好𝑃1（例如，行为序列）来制定指令，评估了我们的模型在经典顺序推荐任务中的性能。

基线。在顺序推荐场景中，我们采用了SASRec [21]和BERT4Rec [33]作为我们的基线。SASRec是一个具有代表性的顺序推荐模型，它利用transformer-encoder架构，结合多头自注意力机制，有效地捕捉数据中的顺序模式。BERT4Rec也广泛应用，它结合了双向自注意力机制，利用填空目标有效地编码顺序数据。性能比较。对于顺序推荐，用户不会主动向系统表达他们的信息需求，这对我们模型的能力构成了一定的限制。然而，通过对大量行为数据进行微调并利用指令的泛化性，如表6所示，我们的模型优于其他基线。此外，我们发现GPT-3.5在这个特定场景中表现并不令人满意。这可以归因于LLM的通用文本性质与私有领域行为信息的特异性之间的不匹配。与自然语言相比，用户行为序列具有高度的个性化和更复杂的特性，这使得通用LLM难以捕捉个人的行为模式。因此，为了在私有领域推荐系统中部署LLM，进行适当的微调而不是仅仅依赖LLM在零镜头设置下可能对于捕捉个性化的用户行为至关重要。

3.2.2 产品搜索 ⟨𝑃0, 𝐼2,𝑇3⟩。在这部分，我们评估了我们的模型在产品搜索上的有效性。一个典型的产品搜索任务从用户那里接收一个搜索查询，然后推荐与查询相关且将被用户点击的项。在这里，搜索查询是通过从目标项的元数据中提取的用户特定意图𝐼2来模拟的，例如目标项类别。

![1708778738741](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778738741.png)

基线。我们采用DSSM [20]作为我们的基线。DSSM是一个经过广泛验证的检索模型，它采用双塔架构，旨在在给定的用户查询和相关文档之间建立语义级别的映射。在我们的实现中，我们利用了以稳健编码能力而闻名的BERT-mini [8]，来表示和编码查询和文档输入。性能比较。对于产品搜索的评估，由于指令相对具体（从项目类别模拟），传统模型表现出色。此外，由于测试集中的项目在训练阶段是不可见的，因此这种评估需要更高的泛化能力。因此，正如我们在表8中所看到的，我们的模型在大多数情况下（尤其是对于顶级排名指标，如NDCG@1）实现了卓越或可比的性能，这归功于其参数中编码的大量通用知识。这一结论也可以从GPT-3.5未经调整的良好结果中得到支持。

3.2.3 个性化搜索 ⟨𝑃1, 𝑃2/𝐼1/𝐼2,𝑇3⟩。在这部分，我们评估了模型在个性化搜索方面的能力，这可以看作是推荐和搜索任务的自然结合。值得注意的是，在个性化搜索的文献[1，10]中，有多种方法可以将个性化注入到传统搜索引擎中，例如在日志中引入用户的历史请求或点击。在本文中，我们遵循以前的工作[1，3]，在后一种设置中进行实验。具体来说，我们利用历史行为序列（𝑃1）进行“个性化”部分。对于“搜索”部分，我们全面采用了由LLM（𝑃2）模拟的用户明确偏好、模糊意图（𝐼1）和具体意图（𝐼2）作为三种类型的查询。

基线。我们在此场景中引入了TEM[3]作为我们的基线。作为个性化产品搜索的代表性方法，TEM利用transformer架构对查询和用户的行为序列进行编码，从而实现对搜索结果中个性化影响的动态控制。性能比较。我们在表7中展示了我们的InstructRec模型在适应个性化搜索方面的性能评估。我们观察到：(1) 总体而言，我们的InstructRec在几乎所有情况下都大大优于其他方法。具体来说，当以用户具体意图（即项目类别）作为指令时，尽管提供了额外的补充信息，如用户行为数据，但GPT-3.5的性能与其进行产品搜索的有效性相比要差。这一观察强调了私有领域数据的用户行为模式与LLM中编码的通用语义知识之间的巨大差距。尽管我们的模型也是建立在通用LLM之上的，但通过使用指令调整技术，它有效地弥补了这一差距，并与推荐系统中的用户个性化行为保持一致。(2) 在用户指令表现出相对模糊性的场景中，例如LLM生成的明确偏好和模糊意图，传统模型的性能往往较差。这可以归因于传统模型无法捕捉这些指令中传达的用户的潜在模糊信息需求。(3) 此外，尽管用户的明确偏好通常是通过分析历史交互来模拟的，并且其中大部分反映了用户的真实偏好，但我们仍然观察到用户的长期主流偏好（𝑃2）与测试集中目标项目的当前意图之间存在不匹配（参见表3中的指令质量评估）。因此，⟨𝑃1, 𝑃2,𝑇3⟩的结果比与用户真实意图更相关的查询的⟨𝑃1, 𝐼2,𝑇3⟩的结果要差得多。不过，指令调整技术的引入使我们的模型具备了推理和泛化能力，从而使其能够处理涉及模糊指令的复杂交互场景。总结来说，通过指令调整，我们的模型有效地将私有领域的用户行为与通用知识整合在一起。因此，它在几乎所有经典的实际任务中都取得了最佳性能，包括序列推荐、产品搜索和个性化搜索，无论用户的偏好是隐式还是显式，意图是模糊还是具体。

![1708778767390](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778767390.png)

![1708778782195](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778782195.png)**3.3 深入分析**

3.3.1 鉴别困难的负面项目候选人。正如之前所述，我们的目标是将模型用作推荐系统中的重新排序器。先前的实验证明了它在重新排序随机采样的候选项目列表中的有效性。为了评估模型在重新排序由强大匹配模块检索到的更实用的候选项目时的能力，这些项目与随机负面项目相比更难区分，我们模拟了推荐的真实“匹配-然后-重新排序”流程。

为此，我们引入了一个匹配模块，以从所有项目中检索候选项目列表，然后我们的模型被指示在顺序推荐的场景中对这些候选人进行重新排序。具体来说，我们采用了经典的双塔模型作为匹配模块。用户塔结合了用户ID、行为序列ID（由2层transformer编码器编码）和行为序列标题（由BERT编码）的信息。项目塔结合了项目ID和项目标题（由BERT编码）的信息。因此，该模块考虑了顺序模式和文本相似性来检索候选项目。

在这个实验中，我们与正面目标项目一起检索了九个负面候选项目。我们模型和其他基准的结果报告在表9中。当重新排序困难的负面候选人时，我们的模型仍然表现出比其他基准更好的性能，并且差距显著。结果表明，我们的模型具有在相似项目中鉴别和选择更符合用户信息需求的项目的强大能力。

![1708778852541](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778852541.png)

3.3.2 鉴别更多候选项目。在之前的实验中，我们通过对十个候选项目列表进行排名，验证了我们的模型在适应不同的交互场景和困难的负面样本方面的有效性。然而，在现实的推荐系统中，经常会遇到数量相当大的项目池（通常数以百计），这些项目满足用户的偏好。为了评估我们的模型在更广泛的候选项目范围内的鉴别能力，我们模拟了一个个性化搜索的重新排序场景。这涉及到了随机抽取的99个负面项目和目标项目，总共形成了100个候选项目。值得注意的是，如前所述，由于上下文长度的限制，我们的模型在同时处理这些候选项目时面临限制。为了完成这次评估，我们采用了一种直接的方法来进行前瞻性测试。具体来说，我们将这一百个候选项目随机分成十个等份，并指示模型从每个组中选择最有可能的项目。然后，将得到的十个项目重新排序，得出我们模型的最终排名结果。如表10所示，我们的模型相较于传统基线具有显著的性能优势。我们还发现，与其他指标相比，HR@1指标观察到的改进相对较小。这可能是由于在十个选定项目之间进行区分的难度增加所致。因此，除了使用具有更长最大上下文长度的LLM之外，该结果还激励我们探索在有限上下文长度约束下可以处理更多候选人的高效算法，这将在未来的工作中进行研究。然而，我们相信我们的InstructRec更适合部署在重新排序阶段（因为它是推荐系统中与用户最接近的阶段），并且现有的匹配模型在实践中能够检索到良好的候选人。

![1708778882051](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778882051.png)

3.3.3 指令的影响。在这部分，我们探索了指令的多样性如何影响模型在未交互场景上的表现，并评估了其泛化能力。为了做到这一点，我们将具有模糊意图的个性化搜索场景设置为未交互场景，并持续添加各种细粒度的指令以进行指令调优。请注意，我们称“模糊意图*”为用户模糊意图的另一种表达，这是从目标评论中模拟出来的。也就是说，由于评论既包含用户偏好又包含项目特性，我们使用教师LLM从项目和用户的角度来分析用户的模糊意图，作为指令调优的训练数据和用于评估的测试数据。

![1708778908105](C:\Users\Administrator\Documents\WeChat Files\wxid_m07cufovnpzz22\FileStorage\Temp\1708778908105.png)

如图3所示，随着用于指令调优的交互场景数量的增加，模型在未交互场景中的性能稳步提高。这一观察结果表明，指令调优在各种场景中的泛化能力是有效的。此外，值得注意的是，“模糊意图*”的引入导致了性能的显著提升，这激励我们通过使用各种策略进行自我指导来标注更多多样化的数据。3.3.4 数据集间的泛化。之前的实验已经证明了我们的模型在容纳未见过的项目、指令和交互场景方面具有显著的泛化能力。尽管这些评估的有效性很高，但大多数评估都集中在域内泛化上。在这部分，我们旨在评估模型在未见过的数据集上的泛化能力，这些数据集与源数据的模式明显不同。为此，我们评估了模型从“游戏”数据集转移到“CD”数据集的能力。结果如表11所示。一般来说，在这种设置下，我们模型的零样本性能仍然与传统的顺序模型相比有所不足，这些模型是在这些域内实例上训练的。这是很自然的，因为在推荐中，域内行为信息至关重要，这在上述评估中已经暗示了。然而，我们的模型仍然大大优于其他擅长零样本任务的强大LLM。这表明指令调优可以为我们的模型带来显著的积极成果，为我们的方法能够有效捕获不同领域之间的通用知识提供了证据。

**4 结论和未来工作**
在本文中，我们提出了一种针对推荐系统的LLM指令调优方法，命名为InstructRec。与现有的将LLM适应于推荐的研究不同，我们的核心思想是将推荐视为LLM遵循的指令，允许用户以自然语言（称为指令）自由表达他们的信息需求。具体来说，我们首先设计了通用指令模板格式，将用户的偏好、意图、任务形式和上下文信息整合到自然语言文本中。然后，我们自动生成了252K个细粒度的用户个性化指令，这些指令描述了用户的偏好和意图。通过对开源LLM（3B Flan-T5-XXL）进行这些指令数据的调优，基础模型可以很好地适应推荐系统，能够遵循用户的指令进行个性化推荐。大量的实验已经证明了我们的方法在各种场景中的有效性和泛化能力。
作为未来的工作，我们将进一步扩大用于指令调优的LLM的规模，并考虑扩展上下文长度以建模长的行为序列。此外，我们将考虑将当前的方法应用于多轮交互场景中，其中用户可以通过闲聊方式与系统进行通信。

